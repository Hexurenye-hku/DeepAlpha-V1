import yfinance as yf
import pandas as pd
import os
import requests  # <--- æ–°å¢è¿™ä¸€è¡Œï¼

# ==========================================
# 1. é…ç½®åŒºåŸŸ (Configuration)
# ==========================================
START_DATE = '2020-01-01'
END_DATE = '2025-01-01'
DATA_PATH = 'data'
PARQUET_FILE = f"{DATA_PATH}/sp500_data.parquet"

# ==========================================
# 2. è·å– S&P 500 åå• (Web Scraping - ä¿®å¤ç‰ˆ)
# ==========================================
def get_sp500_tickers():
    print("ğŸŒ æ­£åœ¨ä»ç»´åŸºç™¾ç§‘æŠ“å– S&P 500 æˆåˆ†è‚¡åå•...")
    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
    
    # ğŸ•µï¸ å…³é”®ä¿®å¤ï¼šä¼ªè£…æˆæµè§ˆå™¨ (User-Agent)
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    try:
        # 1. å…ˆç”¨ requests å¸¦ä¸Šâ€œèº«ä»½è¯â€å»ä¸‹è½½ç½‘é¡µæºç 
        r = requests.get(url, headers=headers)
        
        # 2. æŠŠæºç å–‚ç»™ pandas è§£æ
        table = pd.read_html(r.text)
        df_table = table[0]
        
        tickers = df_table['Symbol'].tolist()
        
        # ä¿®æ­£ä»£ç æ ¼å¼
        tickers = [t.replace('.', '-') for t in tickers]
        
        print(f"âœ… æˆåŠŸè·å– {len(tickers)} åªè‚¡ç¥¨ä»£ç ã€‚")
        return tickers
        
    except Exception as e:
        print(f"âŒ æŠ“å–å¤±è´¥: {e}")
        print("âš ï¸ å¯åŠ¨å¤‡ç”¨åå• (Tech Stocks Only)...")
        # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªå¤‡ç”¨çš„æ ¸å¿ƒåˆ—è¡¨ï¼Œä¿è¯æµç¨‹èƒ½è·‘é€š
        return ['AAPL', 'MSFT', 'GOOG', 'AMZN', 'NVDA', 'TSLA', 'META', 'AMD', 'INTC', 'QCOM', 'JPM', 'BAC', 'GS']

# ==========================================
# 3. æ ¸å¿ƒ ETL é€»è¾‘
# ==========================================
def download_and_clean_data(tickers, start, end):
    print(f"ğŸš€ [Extract] å¼€å§‹æ‰¹é‡ä¸‹è½½ {len(tickers)} åªè‚¡ç¥¨æ•°æ®...")
    print("â˜• è¿™å¯èƒ½éœ€è¦ 1-3 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    # æ‰¹é‡ä¸‹è½½
    # threads=True: å¼€å¯å¤šçº¿ç¨‹ä¸‹è½½ï¼Œé€Ÿåº¦èµ·é£
    raw_data = yf.download(tickers, start=start, end=end, group_by='ticker', auto_adjust=True, threads=True)
    
    print("ğŸ§¹ [Transform] æ­£åœ¨æ¸…æ´—æ•°æ®æ ¼å¼ (Wide -> Long)...")
    
    stack_list = []
    
    # éå†æ‰€æœ‰è‚¡ç¥¨
    for i, ticker in enumerate(tickers):
        try:
            # æå–å•åªè‚¡ç¥¨
            df_single = raw_data[ticker].copy()
            
            # å¦‚æœå…¨æ˜¯ç©ºå€¼ï¼Œè·³è¿‡
            if df_single.dropna(how='all').empty:
                continue
            
            # æ‰“æ ‡ç­¾
            df_single['Ticker'] = ticker
            df_single = df_single.reset_index()
            
            # ä¸ºäº†èŠ‚çœå†…å­˜ï¼Œæˆ‘ä»¬åªä¿ç•™æ ¸å¿ƒåˆ— (æœ‰äº›è‚¡ç¥¨å¯èƒ½æ²¡æœ‰ Volume)
            # è¿™ä¸€æ­¥èƒ½è®©ä½ çš„ Parquet æ–‡ä»¶å˜å°
            cols_to_keep = ['Date', 'Ticker', 'Open', 'High', 'Low', 'Close', 'Volume']
            existing_cols = [c for c in cols_to_keep if c in df_single.columns]
            df_single = df_single[existing_cols]
            
            stack_list.append(df_single)
            
            # è¿›åº¦æ¡æ•ˆæœ (æ¯å¤„ç† 50 åªæ‰“å°ä¸€æ¬¡)
            if (i + 1) % 50 == 0:
                print(f"   å·²å¤„ç† {i + 1}/{len(tickers)} åª...")
                
        except KeyError:
            continue

    # åˆå¹¶
    if stack_list:
        clean_df = pd.concat(stack_list, axis=0)
        
        # æ ‡å‡†åŒ–åˆ—å
        clean_df.columns = [c.lower() for c in clean_df.columns]
        
        # è®¾ç½®ç´¢å¼•
        if 'date' in clean_df.columns and 'ticker' in clean_df.columns:
            clean_df = clean_df.set_index(['date', 'ticker']).sort_index()
        
        print(f"âœ… æ¸…æ´—å®Œæˆï¼æœ€ç»ˆæ•°æ®å½¢çŠ¶: {clean_df.shape}")
        return clean_df
    else:
        print("âŒ æ²¡æœ‰ä»»ä½•æ•°æ®è¢«å¤„ç†")
        return None

# ==========================================
# 4. ä¸»ç¨‹åº
# ==========================================
if __name__ == "__main__":
    if not os.path.exists(DATA_PATH):
        os.makedirs(DATA_PATH)
    
    # 1. åŠ¨æ€è·å–åå•
    sp500_tickers = get_sp500_tickers()
    
    if sp500_tickers:
        # 2. ä¸‹è½½æ•°æ®
        df = download_and_clean_data(sp500_tickers, START_DATE, END_DATE)
        
        # 3. ä¿å­˜
        if df is not None:
            df.to_parquet(PARQUET_FILE)
            file_size = os.path.getsize(PARQUET_FILE) / (1024 * 1024) # è½¬æ¢æˆ MB
            print(f"\nğŸ’¾ [Load] æ•°æ®å·²ä¿å­˜è‡³: {PARQUET_FILE}")
            print(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
            
            # 4. éªŒè¯
            print("\nğŸ” æ•°æ®éªŒè¯ (éšæœºæŠ½æŸ¥):")
            test_read = pd.read_parquet(PARQUET_FILE)
            print(test_read.sample(5)) # éšæœºçœ‹ 5 è¡Œ